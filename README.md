# FRI_Lightswitch

Used an object recognition model (YOLOv5) paired with Azure Kinect color and depth camera to recognize and create an image segmentation of a light switch. 

Would eventually like to pair this to a robotic arm (Universal Robot UR5) to flip the light switch on command. 

<div id="images">
        <img src="images/val_batch0_labels.jpeg" width="350px" height="350px">
        <div style='width: 340px; text-align: center;'>Batch of labeled images.</div>
        <img src="images/point-cloud.png" width="350px" height="350px"> 
        <div style='width: 340px; text-align: center;'>3D reconstruction of lightswitch in pointcloud.</div>
</div>

xfun::embed_file("presentation.pdf")

<object data="presentation.pdf" type="application/pdf" width="700px" height="700px">
    <embed src="presentation.pdf">
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="presentation.pdf">Download PDF</a>.</p>
    </embed>
</object>